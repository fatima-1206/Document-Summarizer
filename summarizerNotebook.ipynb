{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "143bfbc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\fati1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pdfplumber\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import markdown\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import unicodedata\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, pipeline\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.prompts import PromptTemplate\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c211c12",
   "metadata": {},
   "source": [
    "## Document Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75c5a9c",
   "metadata": {},
   "source": [
    "### Data Loading "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b626fa",
   "metadata": {},
   "source": [
    "File Path here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "76203ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './problemStatement.md'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639a0f4b",
   "metadata": {},
   "source": [
    "Get the file extension and parse it accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b7922e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get file extension\n",
    "def get_file_extension(file_path):\n",
    "    return os.path.splitext(file_path)[-1].lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "80804ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the appropriate text parser based on file extension (pdf, markdown, txt)\n",
    "def parse_file(file_path):\n",
    "    file_extension = get_file_extension(file_path)\n",
    "    \n",
    "    if file_extension == '.pdf':\n",
    "        with pdfplumber.open(file_path) as pdf:\n",
    "            text = ''\n",
    "            for page in pdf.pages:\n",
    "                text += page.extract_text() + '\\n'\n",
    "            return text\n",
    "    elif file_extension == '.md' or file_extension == '.markdown':\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            html = markdown.markdown(file.read())\n",
    "        return BeautifulSoup(html, \"html.parser\").get_text()\n",
    "    elif file_extension == '.txt':\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            return f.read()\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file type: {file_extension}\")\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0b58f1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = parse_file(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ec419c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Title: Document Summarization using Retrieval-Augmented\n",
      "Generation (RAG)\n",
      "Objective:\n",
      "To develop a summarization system that combines retrieval-based context\n",
      "selection with large language model (LLM) generation. The system should\n",
      "accept a long document and generate a concise, coherent summary using\n",
      "semantic chunking and RAG.\n",
      "\n",
      "Project Tasks:\n",
      "1. Document Ingestion\n",
      "● Accept documents in PDF, TXT, or Markdown format.\n",
      "● Split into semantically meaningful chunks using sliding windows or\n",
      "semantic segmenters.\n",
      "2. Embedding & Retrieval\n",
      "● Convert chunks to vector embeddings using SentenceTransformers or\n",
      "OpenAI API. ● Store in FAISS or Chroma vector DB.\n",
      "● Perform semantic retrieval for a general summary query (e.g.,\n",
      "\"Summarize this document\").\n",
      "3. Summary Generation\n",
      "● Use top-k retrieved chunks and pass them into a pre-trained LLM\n",
      "(e.g., GPT, LLaMA, Mistral).\n",
      "● Generate a final summary that is coherent, fluent, and accurate.\n",
      "4. Output Presentation\n",
      "● Display the retrieved context and the generated summary. ●\n",
      "Optionally show token usage, latency, and similarity scores.\n",
      "Dataset Suggestions:\n",
      "Dataset\n",
      "ArXiv Abstracts\n",
      "CNN/DailyMail\n",
      "Description\n",
      "\n",
      "Scientific article summaries\n",
      "News article + summary\n",
      "pairs\n",
      "\n",
      "Link\n",
      "\n",
      "https://www.kaggle.com/datasets/Cornell-University/arxiv\n",
      "https://huggingface.co/datasets/cnn_dailymail\n",
      "\n",
      "Custom PDFs Local/public documents\n",
      "for summarization\n",
      "\n",
      "Use your own documents or publicly available\n",
      "datasets\n",
      "\n",
      "Tutorials & Guides\n",
      "● HuggingFace RAG Tutorial:\n",
      "https://huggingface.co/blog/rag\n",
      "● LangChain Quickstart:\n",
      "https://docs.langchain.com/docs/get_started/introduction\n",
      "● FAISS Vector Store Tutorial:\n",
      "https://github.com/facebookresearch/faiss/wiki/Getting-started\n",
      "Research Papers & Articles\n",
      "● Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\n",
      "(Lewis et al., 2020)\n",
      "● Don't Pay Attention: Pay Enough! RAG revisited (Borgeaud et al.,\n",
      "2022) ● ColBERT: Efficient and Effective Passage Retrieval\n",
      "Tools & Libraries\n",
      "● LangChain:\n",
      "https://github.com/hwchase17/langchain\n",
      "● FAISS:\n",
      "https://github.com/facebookresearch/faiss\n",
      "● ChromaDB:\n",
      "https://www.trychroma.com/\n",
      "● SentenceTransformers:\n",
      "https://www.sbert.net/\n",
      "\n",
      "Note to Interns:\n",
      "This is a simplified project focusing on the fundamentals of\n",
      "summarization using pre-trained models and vector search. You are\n",
      "encouraged to be creative and modular in design. We will evaluate your\n",
      "effort and understanding, not just the final output.\n",
      "\n",
      "Submission: ZIP file containing code, a PDF report, and sample\n",
      "results\n",
      "Grading Rubric (100 Points):\n",
      "Category\n",
      "\n",
      "Document Parsing\n",
      "Embedding & Storage\n",
      "Retrieval Quality\n",
      "Summary Generation\n",
      "Pipeline Design\n",
      "Output Presentation\n",
      "Documentation\n",
      "\n",
      "Max Points\n",
      "\n",
      "15\n",
      "15\n",
      "20\n",
      "20\n",
      "10\n",
      "10\n",
      "10\n",
      "\n",
      "Evaluation Criteria\n",
      "\n",
      "Clean loading, chunking, and formatting\n",
      "Efficient use of vector DB and embeddings\n",
      "Relevance of selected content to the document's core idea\n",
      "Fluency, coverage, and accuracy of the summary\n",
      "Clear, modular, and reproducible code\n",
      "Display of retrieved content and generated results\n",
      "ReadMe clarity, report explanation,and visual aids\n",
      "\n",
      "Submission Requirements:\n",
      "● Python code with requirements.txt or environment.yml\n",
      "● ReadMe with setup and usage guide\n",
      "● Sample summarization runs for at least 3 different documents\n",
      "● PDF report (2 pages max)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(raw_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aded9262",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b720e64",
   "metadata": {},
   "source": [
    "Cleaning the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8d4786e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_text(text):\n",
    "    # Normalize line breaks and spaces\n",
    "    text = re.sub(r'\\r\\n|\\r', '\\n', text)           # Convert \\r\\n or \\r to \\n\n",
    "    text = re.sub(r'\\n{2,}', '\\n\\n', text)          # Collapse many newlines into 2\n",
    "    text = re.sub(r'[ \\t]+', ' ', text)             # Remove extra spaces/tabs\n",
    "\n",
    "    # Normalize unicode \n",
    "    text = unicodedata.normalize(\"NFKD\", text)\n",
    "    def add_period_to_bullet(match):\n",
    "        line = match.group(0).strip()\n",
    "        if not line.endswith('.'):\n",
    "            return line + '.'\n",
    "        return line\n",
    "\n",
    "    # Add periods to lines that start with bullet markers (before removing markers)\n",
    "    text = re.sub(r'(?m)^\\s*[-*+]\\s+(.*)', lambda m: \"- \" + add_period_to_bullet(m), text)\n",
    "    # Remove common bullet points\n",
    "    text = re.sub(\n",
    "        r'[\\u2022\\u2023\\u25E6\\u2043\\u2219\\u25AA\\u25AB\\u25CB\\u25CF\\u25A0\\u25B8\\u29BE\\u29BF]',\n",
    "          '', text)\n",
    "\n",
    "    # Remove markdown or ASCII-style tables\n",
    "    text = re.sub(r'\\|.*?\\|', '', text)      # Remove markdown tables\n",
    "    text = re.sub(r'[-=]{3,}', '', text)     # Remove underlines in tables\n",
    "    text = re.sub(r'^\\s*[\\-\\*+]\\s+', '', text, flags=re.MULTILINE)  # Bulleted list lines\n",
    "\n",
    "    # Remove figure/table/image captions\n",
    "    text = re.sub(r'(Figure|Table|Image|Chart|Diagram)\\s*\\d+[\\.:]?', '', text, flags=re.IGNORECASE)\n",
    "\n",
    "    # Remove bracketed footnotes like [1], [12], (Fig. 3), etc.\n",
    "    text = re.sub(r'\\[\\d+\\]', '', text)\n",
    "    text = re.sub(r'\\(.*?fig.*?\\)', '', text, flags=re.IGNORECASE)\n",
    "\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "\n",
    "    # Fix line breaks and hyphens split across lines\n",
    "    text = re.sub(r'-\\n', '', text)  # Remove hyphenated line-breaks\n",
    "    text = re.sub(r'\\n+', '\\n', text)  # Collapse newlines\n",
    "    text = re.sub(r'[ \\t]+', ' ', text)  # Normalize spaces\n",
    "\n",
    "    # Strip remaining non-ASCII or odd symbols\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n",
    "    # before every \\n add a period if it doesn't end with one special character\n",
    "    text = re.sub(r'(?<![.!?:])\\n', '. \\n', text)     \n",
    "\n",
    "    return text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6a429201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Title: Document Summarization using Retrieval-Augmented. \n",
      "Generation (RAG). \n",
      "Objective:\n",
      "To develop a summarization system that combines retrieval-based context. \n",
      "selection with large language model (LLM) generation. The system should. \n",
      "accept a long document and generate a concise, coherent summary using. \n",
      "semantic chunking and RAG.\n",
      "Project Tasks:\n",
      "1. Document Ingestion. \n",
      " Accept documents in PDF, TXT, or Markdown format.\n",
      " Split into semantically meaningful chunks using sliding windows or. \n",
      "semantic segmenters.\n",
      "2. Embedding & Retrieval. \n",
      " Convert chunks to vector embeddings using SentenceTransformers or. \n",
      "OpenAI API. Store in FAISS or Chroma vector DB.\n",
      " Perform semantic retrieval for a general summary query (e.g.,. \n",
      "\"Summarize this document\").\n",
      "3. Summary Generation. \n",
      " Use top-k retrieved chunks and pass them into a pre-trained LLM. \n",
      "(e.g., GPT, LLaMA, Mistral).\n",
      " Generate a final summary that is coherent, fluent, and accurate.\n",
      "4. Output Presentation. \n",
      " Display the retrieved context and the generated summary. . \n",
      "Optionally show token usage, latency, and similarity scores.\n",
      "Dataset Suggestions:\n",
      "Dataset. \n",
      "ArXiv Abstracts. \n",
      "CNN/DailyMail. \n",
      "Description. \n",
      "Scientific article summaries. \n",
      "News article + summary. \n",
      "pairs. \n",
      "Link. \n",
      "Custom PDFs Local/public documents. \n",
      "for summarization. \n",
      "Use your own documents or publicly available. \n",
      "datasets. \n",
      "Tutorials & Guides. \n",
      " HuggingFace RAG Tutorial:\n",
      " LangChain Quickstart:\n",
      " FAISS Vector Store Tutorial:\n",
      "Research Papers & Articles. \n",
      " Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks. \n",
      "(Lewis et al., 2020). \n",
      " Don't Pay Attention: Pay Enough! RAG revisited (Borgeaud et al.,. \n",
      "2022) ColBERT: Efficient and Effective Passage Retrieval. \n",
      "Tools & Libraries. \n",
      " LangChain:\n",
      " FAISS:\n",
      " ChromaDB:\n",
      " SentenceTransformers:\n",
      "Note to Interns:\n",
      "This is a simplified project focusing on the fundamentals of. \n",
      "summarization using pre-trained models and vector search. You are. \n",
      "encouraged to be creative and modular in design. We will evaluate your. \n",
      "effort and understanding, not just the final output.\n",
      "Submission: ZIP file containing code, a PDF report, and sample. \n",
      "results. \n",
      "Grading Rubric (100 Points):\n",
      "Category. \n",
      "Document Parsing. \n",
      "Embedding & Storage. \n",
      "Retrieval Quality. \n",
      "Summary Generation. \n",
      "Pipeline Design. \n",
      "Output Presentation. \n",
      "Documentation. \n",
      "Max Points. \n",
      "15. \n",
      "15. \n",
      "20. \n",
      "20. \n",
      "10. \n",
      "10. \n",
      "10. \n",
      "Evaluation Criteria. \n",
      "Clean loading, chunking, and formatting. \n",
      "Efficient use of vector DB and embeddings. \n",
      "Relevance of selected content to the document's core idea. \n",
      "Fluency, coverage, and accuracy of the summary. \n",
      "Clear, modular, and reproducible code. \n",
      "Display of retrieved content and generated results. \n",
      "ReadMe clarity, report explanation,and visual aids. \n",
      "Submission Requirements:\n",
      " Python code with requirements.txt or environment.yml. \n",
      " ReadMe with setup and usage guide. \n",
      " Sample summarization runs for at least 3 different documents. \n",
      " PDF report (2 pages max).\n"
     ]
    }
   ],
   "source": [
    "text = clean_text(raw_text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058adda6",
   "metadata": {},
   "source": [
    "## Chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78cb07c",
   "metadata": {},
   "source": [
    "Download the embedding model from hugging face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7ea0e617",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24ac218",
   "metadata": {},
   "source": [
    "We will be using the semantic Chunker from langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2266552f",
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_chunker = SemanticChunker(embedding_model, breakpoint_threshold_type=\"percentile\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "662cc2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = semantic_chunker.split_text(text)\n",
    "\n",
    "metadatas = [\n",
    "    {\n",
    "        \"source\": file_path,\n",
    "        \"chunk_index\": i,\n",
    "        \"length\": len(chunks[i])\n",
    "\n",
    "    }\n",
    "    for i in range(len(chunks))\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a234ff5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of chunks: 6\n",
      "\n",
      "Chunk 1 length: 1208 characters\n",
      "Chunk 1:\n",
      "Project Title: Document Summarization using Retrieval-Augmented. Generation (RAG). Objective:\n",
      "To develop a summarization system that combines retrieval-based context. selection with large language model (LLM) generation. The system should. accept a long document and generate a concise, coherent summary using. semantic chunking and RAG. Project Tasks:\n",
      "1. Document Ingestion. Accept documents in PDF, TXT, or Markdown format. Split into semantically meaningful chunks using sliding windows or. semantic segmenters. 2. Embedding & Retrieval. Convert chunks to vector embeddings using SentenceTransformers or. OpenAI API. Store in FAISS or Chroma vector DB. Perform semantic retrieval for a general summary query (e.g.,. \"Summarize this document\"). 3. Summary Generation. Use top-k retrieved chunks and pass them into a pre-trained LLM. (e.g., GPT, LLaMA, Mistral). Generate a final summary that is coherent, fluent, and accurate. 4. Output Presentation. Display the retrieved context and the generated summary. . Optionally show token usage, latency, and similarity scores. Dataset Suggestions:\n",
      "Dataset. ArXiv Abstracts. CNN/DailyMail. Description. Scientific article summaries. News article + summary. pairs.\n",
      "\n",
      "Chunk 2 length: 331 characters\n",
      "Chunk 2:\n",
      "Link. Custom PDFs Local/public documents. for summarization. Use your own documents or publicly available. datasets. Tutorials & Guides. HuggingFace RAG Tutorial:\n",
      " LangChain Quickstart:\n",
      " FAISS Vector Store Tutorial:\n",
      "Research Papers & Articles. Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks. (Lewis et al., 2020).\n",
      "\n",
      "Chunk 3 length: 341 characters\n",
      "Chunk 3:\n",
      "Don't Pay Attention: Pay Enough! RAG revisited (Borgeaud et al.,. 2022) ColBERT: Efficient and Effective Passage Retrieval. Tools & Libraries. LangChain:\n",
      " FAISS:\n",
      " ChromaDB:\n",
      " SentenceTransformers:\n",
      "Note to Interns:\n",
      "This is a simplified project focusing on the fundamentals of. summarization using pre-trained models and vector search. You are.\n",
      "\n",
      "Chunk 4 length: 197 characters\n",
      "Chunk 4:\n",
      "encouraged to be creative and modular in design. We will evaluate your. effort and understanding, not just the final output. Submission: ZIP file containing code, a PDF report, and sample. results.\n",
      "\n",
      "Chunk 5 length: 154 characters\n",
      "Chunk 5:\n",
      "Grading Rubric (100 Points):\n",
      "Category. Document Parsing. Embedding & Storage. Retrieval Quality. Summary Generation. Pipeline Design. Output Presentation.\n",
      "\n",
      "Chunk 6 length: 612 characters\n",
      "Chunk 6:\n",
      "Documentation. Max Points. 15. 15. 20. 20. 10. 10. 10. Evaluation Criteria. Clean loading, chunking, and formatting. Efficient use of vector DB and embeddings. Relevance of selected content to the document's core idea. Fluency, coverage, and accuracy of the summary. Clear, modular, and reproducible code. Display of retrieved content and generated results. ReadMe clarity, report explanation,and visual aids. Submission Requirements:\n",
      " Python code with requirements.txt or environment.yml. ReadMe with setup and usage guide. Sample summarization runs for at least 3 different documents. PDF report (2 pages max).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total number of chunks: {len(chunks)}\\n\")\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Chunk {i+1} length: {len(chunk)} characters\")\n",
    "    print(f\"Chunk {i+1}:\\n{chunk}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f74c726",
   "metadata": {},
   "source": [
    "## Vector Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "76d69730",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Chroma(\n",
    "    persist_directory=\"chroma_store\",\n",
    "    embedding_function=embedding_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4870864",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = list(set(chunks))  \n",
    "db.add_texts( texts=chunks, metadatas=metadatas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e15fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fati1\\AppData\\Local\\Temp\\ipykernel_13220\\123899826.py:1: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  db.persist()\n"
     ]
    }
   ],
   "source": [
    "db.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7afaad",
   "metadata": {},
   "source": [
    "## Query Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dea59fd",
   "metadata": {},
   "source": [
    "Embedd the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03913b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is the project about?\"\n",
    "query_embedding = embedding_model.embed_query(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a179c79a",
   "metadata": {},
   "source": [
    "## Similarity Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4002b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the chroma store act like a retriever\n",
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecf9d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform the similarity search to get the most relevant chunks\n",
    "results = retriever.get_relevant_documents(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c775b3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is the project about?\n",
      "\n",
      "Result 1:\n",
      "encouraged to be creative and modular in design. We will evaluate your. effort and understanding, not just the final output. Submission: ZIP file containing code, a PDF report, and sample. results.\n",
      "\n",
      "Metadata: {'source': './problemStatement.md', 'chunk_index': 3, 'length': 197}\n",
      "\n",
      "Result 2:\n",
      "Documentation. Max Points. 15. 15. 20. 20. 10. 10. 10. Evaluation Criteria. Clean loading, chunking, and formatting. Efficient use of vector DB and embeddings. Relevance of selected content to the document's core idea. Fluency, coverage, and accuracy of the summary. Clear, modular, and reproducible code. Display of retrieved content and generated results. ReadMe clarity, report explanation,and visual aids. Submission Requirements:\n",
      " Python code with requirements.txt or environment.yml. ReadMe with setup and usage guide. Sample summarization runs for at least 3 different documents. PDF report (2 pages max).\n",
      "\n",
      "Metadata: {'source': './problemStatement.md', 'chunk_index': 5, 'length': 612}\n",
      "\n",
      "Result 3:\n",
      "Grading Rubric (100 Points):\n",
      "Category. Document Parsing. Embedding & Storage. Retrieval Quality. Summary Generation. Pipeline Design. Output Presentation.\n",
      "\n",
      "Metadata: {'source': './problemStatement.md', 'chunk_index': 4, 'length': 154}\n",
      "\n",
      "Result 4:\n",
      "Link. Custom PDFs Local/public documents. for summarization. Use your own documents or publicly available. datasets. Tutorials & Guides. HuggingFace RAG Tutorial:\n",
      " LangChain Quickstart:\n",
      " FAISS Vector Store Tutorial:\n",
      "Research Papers & Articles. Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks. (Lewis et al., 2020).\n",
      "\n",
      "Metadata: {'source': './problemStatement.md', 'length': 331, 'chunk_index': 1}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Query: {query}\\n\")\n",
    "for i, result in enumerate(results):\n",
    "    print(f\"Result {i+1}:\\n{result.page_content}\\n\")\n",
    "    print(f\"Metadata: {result.metadata}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cc384d",
   "metadata": {},
   "source": [
    "## LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1e796f",
   "metadata": {},
   "source": [
    "### Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3486593a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "summarization_model = AutoModelForSeq2SeqLM.from_pretrained(\"sshleifer/distilbart-cnn-12-6\")\n",
    "summarization_model_name = \"sshleifer/distilbart-cnn-12-6\"\n",
    "tokenizer_sum = AutoTokenizer.from_pretrained(summarization_model_name)\n",
    "model_sum = AutoModelForSeq2SeqLM.from_pretrained(summarization_model_name)\n",
    "\n",
    "pipe_sum = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=model_sum,\n",
    "    tokenizer=tokenizer_sum,\n",
    "    max_length=1024\n",
    ")\n",
    "\n",
    "# Wrap it with LangChain\n",
    "llm_sum = HuggingFacePipeline(pipeline=pipe_sum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f551796",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_summary(vectorstore, llm_sum, k=5):\n",
    "    \n",
    "    collection = vectorstore._collection\n",
    "    all_docs = collection.get(include=[\"documents\", \"embeddings\"])\n",
    "\n",
    "    if all_docs[\"embeddings\"] is None or len(all_docs[\"embeddings\"]) == 0:\n",
    "        raise ValueError(\"No embeddings found in the vectorstore!\")\n",
    "\n",
    "    embeddings = np.array(all_docs[\"embeddings\"])\n",
    "    documents = all_docs[\"documents\"]\n",
    "\n",
    "    # Computing the centroid of all embeddings\n",
    "    centroid = np.mean(embeddings, axis=0).reshape(1, -1)\n",
    "\n",
    "    salience_scores = np.linalg.norm(embeddings - centroid, axis=1)\n",
    "\n",
    "    # Step 4: Get indices of the top-k most salient chunks\n",
    "    top_k_indices = salience_scores.argsort()[::-1][:k]\n",
    "    salient_chunks = [documents[i] for i in top_k_indices]\n",
    "\n",
    "    input_text = \"You are an academic writing assistant. Summarize the following document in elegant, natural language. Make sure it reads smoothly and sounds professional. Avoid copying bullet points verbatim. Use proper grammar and punctuation.\\n\"\n",
    "    input_text = \" \".join(salient_chunks)\n",
    "    # print(f\"Input text length for summarization: {len(input_text)} characters\")\n",
    "    # print(f\"Input text:\\n{input_text}\\n\")\n",
    "    if len(input_text) > 3000:  \n",
    "        input_text = input_text[:3000]\n",
    "\n",
    "    summary = llm_sum.invoke(input_text)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fb7f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " This is a simplified project focusing on the fundamentals of summarization using pre-trained models and vector search . The system should accept a long document and generate a concise, coherent summary using semantic chunking and RAG . We will evaluate your effort and understanding, not just the final output .\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    get_summary_from_central_chunks(db, llm_sum, k=5)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dc0ea3",
   "metadata": {},
   "source": [
    "### General Query Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93146b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "model_name = \"google/flan-t5-base\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=512\n",
    ")\n",
    "\n",
    "# Wrap it with LangChain\n",
    "llm = HuggingFacePipeline(pipeline=pipe)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626752a3",
   "metadata": {},
   "source": [
    "Now generating the final prompt by combining the query and the chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2712e8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\\n\\n\".join([doc.page_content for doc in results[0:1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23484eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=\"\"\"\n",
    "    Use the following context to answer the question at the end. \n",
    "    Even if the question is not directly answered in the context, say \"It's not clearly mentioned but my best guess is\"\n",
    "    and use the context to provide a guess.\n",
    "    Give a detailed answer based on the context provided.\n",
    "    Context:\n",
    "    {context}\n",
    "\n",
    "    Question:\n",
    "    {question}\n",
    "\n",
    "    Answer:\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2deff68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "rag_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt_template\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ea7317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will evaluate your effort and understanding, not just the final output. Submission: ZIP file containing code, a PDF report, and sample. results.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "response = rag_chain.run({\n",
    "    \"context\": context,\n",
    "    \"question\": query\n",
    "})\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e396467",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.delete_collection()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
